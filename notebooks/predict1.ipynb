{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57968,"status":"ok","timestamp":1734828075684,"user":{"displayName":"Yoav Zelinger","userId":"13221241970274122758"},"user_tz":-120},"id":"6AaF5_zU_wkn","outputId":"bf5283f0-dc8d-4192-ac60-9e064d7805de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Adjusting current working directory to parent directory\n","from pathlib import Path\n","from os import chdir\n","from platform import system\n","\n","try:\n","    current_directory\n","except: # First  run - initialize current_directory\n","    current_directory = Path.cwd()\n","    if system() == \"Linux\": # Colab\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        current_directory = f\"{current_directory}/drive/MyDrive/Colab Notebooks/RecTour2024Challenge\"\n","    else:\n","        current_directory = current_directory.parent\n","finally:\n","    chdir(current_directory)\n","\n","\n","\n","# External imports\n","import pandas as pd\n","import numpy as np\n","\n","from random import randint\n","\n","import torch\n","import torch.nn as nn\n","\n","from sentence_transformers import SentenceTransformer\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.models import load_model\n","\n","\n","\n","# Internal imports\n","from src.data.csv_tools import csv_to_dataframe, dataframe_to_csv, save_submission\n","from src.data.pickle_tools import save_to_pickle, load_pickle\n","from src.data.keras_tools import save_keras_model, load_keras_model\n","from src.utils.preprocessing_tools import *"]},{"cell_type":"markdown","metadata":{"id":"Wkrz0oRx_wko"},"source":["STEP 1 - Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LG_NCTBy_wko"},"outputs":[],"source":["test_users_df = csv_to_dataframe(\"test\", \"users\")\n","users_embeddings_dict = load_pickle(\"test_user_embeddings_dict\")\n","title_vectors_dict = load_pickle(\"test_title_vectors_dict\")\n","positive_vectors_dict = load_pickle(\"test_positive_vectors_dict\")\n","negative_vectors_dict = load_pickle(\"test_negative_vectors_dict\")\n","accomodation_reviews_dict = load_pickle(\"test_reviews_grouped_by_accommodation\")"]},{"cell_type":"markdown","metadata":{"id":"Mc4FA6vk_wko"},"source":["STEP 2 - Load models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXcL2fZSNTPU"},"outputs":[],"source":["def create_contrastive_model():\n","    user_input = Input(shape=(12,), name='user')\n","    user_dense = Dense(384, activation='relu', name='user_dense')(user_input)\n","\n","    review_input = Input(shape=(384,), name='review')\n","\n","    cosine_similarity = Lambda(lambda tensors: tf.reduce_sum(tensors[0] * tensors[1], axis=-1, keepdims=True)) \\\n","                              ([user_dense, review_input])\n","\n","    return Model([user_input, review_input], cosine_similarity, name='contrastive_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FYYLuogf_wkp"},"outputs":[],"source":["title_model = create_contrastive_model()\n","title_model.load_weights(\"title_model.h5\")\n","positive_model = create_contrastive_model()\n","positive_model.load_weights(\"positive_model.h5\")\n","negative_model = create_contrastive_model()\n","negative_model.load_weights(\"negative_model.h5\")"]},{"cell_type":"markdown","metadata":{"id":"NVMVOwQ4_wkp"},"source":["STEP 3 - Prepare the input to the models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGdnh1u7_wkp"},"outputs":[],"source":["def get_model_input(user_id, accommodation_id):\n","    user_embedding = users_embeddings_dict[user_id]\n","    accomodation_reviews_ids = accomodation_reviews_dict[accommodation_id]\n","    titles_embeddings = [title_vectors_dict[review_id] for review_id in accomodation_reviews_ids]\n","    positive_embeddings = [positive_vectors_dict[review_id] for review_id in accomodation_reviews_ids]\n","    negative_embeddings = [negative_vectors_dict[review_id] for review_id in accomodation_reviews_ids]\n","    user_embedding = np.array([user_embedding] * len(titles_embeddings))\n","    titles_embeddings = np.array(titles_embeddings)\n","    positive_embeddings = np.array(positive_embeddings)\n","    negative_embeddings = np.array(negative_embeddings)\n","    return [user_embedding, titles_embeddings], [user_embedding, positive_embeddings], [user_embedding, negative_embeddings]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KBPKA4lbEXF"},"outputs":[],"source":["# Create df - Structure: accommodation_id,user_id,review_1,review_2,review_3,...,review_10\n","columns = [\"accommodation_id\", \"user_id\"] + [f\"review_{i}\" for i in range(1, 11)]\n","submission_df = pd.DataFrame(columns=columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1734828098089,"user":{"displayName":"Yoav Zelinger","userId":"13221241970274122758"},"user_tz":-120},"id":"RrzNrRlLdzIJ","outputId":"7d50e433-3697-4288-f100-3497cb19b839"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n","  return bound(*args, **kwds)\n"]}],"source":["split_dfs = np.array_split(test_users_df, 20)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1734828098090,"user":{"displayName":"Yoav Zelinger","userId":"13221241970274122758"},"user_tz":-120},"id":"NxYPICu-dzIJ","outputId":"13d3e867-51fa-457e-dd48-667949091dc1"},"outputs":[{"data":{"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n","\n","Data structure also contains labeled axes (rows and columns).\n","Arithmetic operations align on both row and column labels. Can be\n","thought of as a dict-like container for Series objects. The primary\n","pandas data structure.\n","\n","Parameters\n","----------\n","data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n","    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n","    data is a dict, column order follows insertion-order. If a dict contains Series\n","    which have an index defined, it is aligned by its index. This alignment also\n","    occurs if data is a Series or a DataFrame itself. Alignment is done on\n","    Series/DataFrame inputs.\n","\n","    If data is a list of dicts, column order follows insertion-order.\n","\n","index : Index or array-like\n","    Index to use for resulting frame. Will default to RangeIndex if\n","    no indexing information part of input data and no index provided.\n","columns : Index or array-like\n","    Column labels to use for resulting frame when data does not have them,\n","    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n","    will perform column selection instead.\n","dtype : dtype, default None\n","    Data type to force. Only a single dtype is allowed. If None, infer.\n","copy : bool or None, default None\n","    Copy data from inputs.\n","    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n","    or 2d ndarray input, the default of None behaves like ``copy=False``.\n","    If data is a dict containing one or more Series (possibly of different dtypes),\n","    ``copy=False`` will ensure that these inputs are not copied.\n","\n","    .. versionchanged:: 1.3.0\n","\n","See Also\n","--------\n","DataFrame.from_records : Constructor from tuples, also record arrays.\n","DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n","read_csv : Read a comma-separated values (csv) file into DataFrame.\n","read_table : Read general delimited file into DataFrame.\n","read_clipboard : Read text from clipboard into DataFrame.\n","\n","Notes\n","-----\n","Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n","\n","Examples\n","--------\n","Constructing DataFrame from a dictionary.\n","\n","&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n","&gt;&gt;&gt; df = pd.DataFrame(data=d)\n","&gt;&gt;&gt; df\n","   col1  col2\n","0     1     3\n","1     2     4\n","\n","Notice that the inferred dtype is int64.\n","\n","&gt;&gt;&gt; df.dtypes\n","col1    int64\n","col2    int64\n","dtype: object\n","\n","To enforce a single dtype:\n","\n","&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n","&gt;&gt;&gt; df.dtypes\n","col1    int8\n","col2    int8\n","dtype: object\n","\n","Constructing DataFrame from a dictionary including Series:\n","\n","&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n","&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n","   col1  col2\n","0     0   NaN\n","1     1   NaN\n","2     2   2.0\n","3     3   3.0\n","\n","Constructing DataFrame from numpy ndarray:\n","\n","&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n","...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n","&gt;&gt;&gt; df2\n","   a  b  c\n","0  1  2  3\n","1  4  5  6\n","2  7  8  9\n","\n","Constructing DataFrame from a numpy ndarray that has labeled columns:\n","\n","&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n","...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n","&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n","...\n","&gt;&gt;&gt; df3\n","   c  a\n","0  3  1\n","1  6  4\n","2  9  7\n","\n","Constructing DataFrame from dataclass:\n","\n","&gt;&gt;&gt; from dataclasses import make_dataclass\n","&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n","&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n","   x  y\n","0  0  0\n","1  0  3\n","2  2  3\n","\n","Constructing DataFrame from Series/DataFrame:\n","\n","&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df\n","   0\n","a  1\n","c  3\n","\n","&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n","&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df2\n","   x\n","a  1\n","c  3</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 509);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"],"text/plain":["pandas.core.frame.DataFrame"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["type(test_users_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jhjM2adO_wkp","outputId":"e3cb2a7c-6d6a-4e67-8f39-772d0478a9b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current index: 100000\n","Current index: 102000\n","Current index: 104000\n","Current index: 106000\n","Current index: 108000\n","Current index: 110000\n","Current index: 112000\n","Current index: 114000\n","Current index: 116000\n","Current index: 118000\n","Current index: 120000\n","Current index: 122000\n","Current index: 124000\n","Current index: 126000\n","Current index: 128000\n","Current index: 130000\n","Current index: 132000\n","Current index: 134000\n","Current index: 136000\n","Current index: 138000\n","Current index: 140000\n","Current index: 142000\n","Current index: 144000\n","Current index: 146000\n","Current index: 148000\n","Current index: 150000\n","Current index: 152000\n","Current index: 154000\n","Current index: 156000\n","Current index: 158000\n","Current index: 160000\n","Current index: 162000\n","Current index: 164000\n","Current index: 166000\n","Current index: 168000\n","Current index: 170000\n","Current index: 172000\n","Current index: 174000\n","Current index: 176000\n","Current index: 178000\n","Current index: 180000\n","Current index: 182000\n","Current index: 184000\n","Current index: 186000\n","Current index: 188000\n","Current index: 190000\n","Current index: 192000\n","Current index: 194000\n","Current index: 196000\n","Current index: 198000\n"]}],"source":["for index, split_dfs in enumerate(split_dfs[15: ], 15):\n","  submission_df = pd.DataFrame(columns=columns)\n","  for current_user_index, row in split_dfs.iterrows():\n","      if current_user_index % 2000 == 0:\n","          print(f\"Current index: {current_user_index}\")\n","      user_id = row[\"user_id\"]\n","      accomodation_id = row[\"accommodation_id\"]\n","      title_input, positive_input, negative_input = get_model_input(user_id, accomodation_id)\n","      # title_prediction = title_model.predict(title_input, verbose = 0)\n","      positive_prediction = positive_model.predict(positive_input, verbose = 0)\n","      # negative_prediction = negative_model.predict(negative_input, verbose = 0)\n","      # Get the top 10 reviews where the average is the highest\n","      top_10_reviews = []\n","      for i in range(len(positive_prediction)):\n","          top_10_reviews.append(positive_prediction[i][0])\n","      top_10_reviews = np.argsort(top_10_reviews)[-10:][::-1]\n","      reviews = [accomodation_reviews_dict[accomodation_id][i] for i in top_10_reviews]\n","      submission_df = submission_df._append(pd.Series([accomodation_id, user_id] + reviews, index=columns), ignore_index=True)\n","\n","  dataframe_to_csv(submission_df, f\"SubmissionPart{index}.csv\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}